# Data Preparation
We utilize two datsets: COCO Captions (COCO), Flickr 30K Captions (F30K).
We extract all image feature by a FasterRCNN detector provided by [URL](https://github.com/peteanderson80/bottom-up-attention "bottom-up-attention").
You can directly download the precomputed dataset we prepared.
## MSCOCO
```
data
│   
└───coco_precomp
   │   train_100featc32.npy
   │   train_caps.txt.bt
   │   test_100featc32.npy
   │   test_caps.txt.bt
```

[train_100featc32.npy](https://drive.google.com/file/d/1EAYp_uhoKfohSONNGVro2bSQjiB3G5Be/view?usp=sharing)
[train_caps.txt.bt](https://drive.google.com/file/d/1Jp4hvQFXhRFZ9z97sdBprpZpFbT6NMHN/view?usp=sharing)
[test_100featc32.npy](https://drive.google.com/file/d/1sO0SaNou1qL1EVe1bvgfE2ewHuzcb8vS/view?usp=sharing)
[test_caps.txt.bt](https://drive.google.com/file/d/1dtYdWM41i2yvHB0zlJLWnWRDwalncjFG/view?usp=sharing)